{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 一. 构建两个场景链",
   "id": "214dd3aba291436c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-09T10:27:46.829351Z",
     "start_time": "2024-08-09T10:27:46.789348Z"
    }
   },
   "source": [
    "\n",
    "# 构建两个场景的模板\n",
    "flower_care_template = \"\"\"\n",
    "你是一个经验丰富的园丁，擅长解答关于养花育花的问题。\n",
    "下面是需要你来回答的问题:\n",
    "{input}\n",
    "\"\"\"\n",
    "flower_deco_template = \"\"\"\n",
    "你是一位网红插花大师，擅长解答关于鲜花装饰的问题。\n",
    "下面是需要你来回答的问题:\n",
    "{input}\n",
    "\"\"\"\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"key\": \"flower_care\",\n",
    "        \"description\": \"适合回答关于鲜花护理的问题\",\n",
    "        \"template\": flower_care_template,\n",
    "    },\n",
    "    {\n",
    "        \"key\": \"flower_decoration\",\n",
    "        \"description\": \"适合回答关于鲜花装饰的问题\",\n",
    "        \"template\": flower_deco_template,\n",
    "    }\n",
    "]\n",
    "\n",
    "# 构建目标链 ：构建出两个目标链，分别负责处理不同的问题。\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI()\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "chain_map = {}\n",
    "# 构建多个基础chain\n",
    "for info in prompt_infos:\n",
    "    prompt = PromptTemplate(\n",
    "        template=info['template'],\n",
    "        input_variables=[\"input\"]\n",
    "    )\n",
    "    print(\"目标提示:\\n\", prompt)\n",
    "    # chain = prompt | llm\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=True # 控制程序输出详细程度的常见参数。\n",
    "    )\n",
    "    # 放到chain_map中\n",
    "    chain_map[info[\"key\"]] = chain"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标提示:\n",
      " input_variables=['input'] template='\\n你是一个经验丰富的园丁，擅长解答关于养花育花的问题。\\n下面是需要你来回答的问题:\\n{input}\\n'\n",
      "目标提示:\n",
      " input_variables=['input'] template='\\n你是一位网红插花大师，擅长解答关于鲜花装饰的问题。\\n下面是需要你来回答的问题:\\n{input}\\n'\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 二. 构建路由链：用于选择链",
   "id": "ac4b6650a96ef83c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T10:27:49.717308Z",
     "start_time": "2024-08-09T10:27:49.714344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE as RounterTemplate\n",
    "\n",
    "# 路由模版\n",
    "# 之前的prompts构建router_template\n",
    "# 组合成一个字符串，格式为 \"key: description\"。\n",
    "destinations = [f\"{p['key']}: {p['description']}\" for p in prompt_infos]\n",
    "router_template = RounterTemplate.format(destinations=\"\\n\".join(destinations))\n",
    "print(\"路由模板:\\n\", router_template)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "print(\"路由提示:\\n\", router_prompt)\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm,\n",
    "    router_prompt,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "5c82d54e3bf3626a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "路由模板:\n",
      " Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "flower_care: 适合回答关于鲜花护理的问题\n",
      "flower_decoration: 适合回答关于鲜花装饰的问题\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n",
      "路由提示:\n",
      " input_variables=['input'] output_parser=RouterOutputParser() template='Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{{\\n    \"destination\": string \\\\ name of the prompt to use or \"DEFAULT\"\\n    \"next_inputs\": string \\\\ a potentially modified version of the original input\\n}}\\n```\\n\\nREMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\\nREMEMBER: \"next_inputs\" can just be the original input if you don\\'t think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\nflower_care: 适合回答关于鲜花护理的问题\\nflower_decoration: 适合回答关于鲜花装饰的问题\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT (must include ```json at the start of the response) >>\\n<< OUTPUT (must end with ```) >>\\n'\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. 构建默认链",
   "id": "a6dfc2f4603e8996"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "from langchain.chains import ConversationChain\n",
    "# 如果其他两个链都没有选择时，就走默认链\n",
    "default_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=router_prompt,\n",
    "    output_key=\"text\",\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "2a12a74af24dceeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. 构建多提示链",
   "id": "a463fd7ec690f3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T10:28:47.809032Z",
     "start_time": "2024-08-09T10:28:47.806791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 构建多提示链\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=chain_map,  \n",
    "    default_chain=default_chain\n",
    ")"
   ],
   "id": "5287ff73522aff59",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:10.112270Z",
     "start_time": "2024-08-09T10:28:59.845403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 测试1\n",
    "print(chain.run(\"如何为玫瑰浇水？\"))\n",
    "# 测试2              \n",
    "print(chain.run(\"如何为婚礼场地装饰花朵？\"))\n",
    "# 测试3         \n",
    "print(chain.run(\"如何区分阿豆和罗豆？\"))"
   ],
   "id": "8d30f53f5d09a6b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lianggao/miniconda3/envs/langchain-demo/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "你是一个经验丰富的园丁，擅长解答关于养花育花的问题。\n",
      "下面是需要你来回答的问题:\n",
      "如何为玫瑰浇水？\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "1. 观察土壤湿度：首先要根据玫瑰所在的环境和季节来判断是否需要浇水。一般来说，土壤表面干燥了一两厘米就可以浇水了，但是如果土壤表面还有一些湿润的部分，就不需要浇水。\n",
      "\n",
      "2. 浇水的时间：最好选择在早晨或者傍晚浇水，避免在白天阳光强烈的时候浇水，这样可以减少水分蒸发的损失。\n",
      "\n",
      "3. 使用适量的水：浇水时，要注意水的量，不要过少也不要过多。一般来说，每次浇水的量应该是花盆容量的1/3左右，这样可以保证水分充足，但又避免积水导致根部\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "你是一位网红插花大师，擅长解答关于鲜花装饰的问题。\n",
      "下面是需要你来回答的问题:\n",
      "如何为婚礼场地装饰花朵？\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "首先，为婚礼场地装饰花朵需要考虑以下几点：\n",
      "1. 主题概念：根据新人的喜好和婚礼主题，选择相应的花材和色彩，营造出浪漫、温馨或者奢华的氛围。\n",
      "2. 场地布置：根据场地的大小和布局，确定花艺摆放的位置和方式，可以选择在入口处、舞台、桌上等位置装饰花朵。\n",
      "3. 花材选择：要考虑到季节、花材的耐久性和价格，可以选择鲜花、干花、人造花等不同材质的花卉搭配使用。\n",
      "4. 色彩搭配：花朵的颜色可以与新人的服装、场地的装饰和氛围\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "flower_care: 适合回答关于鲜花护理的问题\n",
      "flower_decoration: 适合回答关于鲜花装饰的问题\n",
      "\n",
      "<< INPUT >>\n",
      "如何区分阿豆和罗豆？\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"destination\": \"DEFAULT\",\n",
      "    \"next_inputs\": \"如何区分阿豆和罗豆？\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ebfb36fc159d22f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo",
   "language": "python",
   "name": "langchain-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
