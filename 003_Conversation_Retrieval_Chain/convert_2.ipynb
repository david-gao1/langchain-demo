{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. 加载要索引的数据。  \n",
    "# 使用WebBaseLoader加载网页数据  \n",
    "from langchain_community.document_loaders import WebBaseLoader  \n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")  \n",
    "docs = loader.load()  \n",
    "  \n",
    "# 2. 文档分片，并通过向量存储构建文档索引   \n",
    "from langchain_openai import OpenAIEmbeddings  \n",
    "embeddings = OpenAIEmbeddings()  \n",
    "# FAISS：轻量化的本地存储  \n",
    "from langchain_community.vectorstores import FAISS  \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  \n",
    "#文档分片\n",
    "text_splitter = RecursiveCharacterTextSplitter()  \n",
    "documents = text_splitter.split_documents(docs)  \n",
    "# 分片数据添加索引\n",
    "vector = FAISS.from_documents(documents, embeddings)  \n",
    "  \n",
    "\n",
    "# 索引转为检索器 \n",
    "from langchain.chains import create_retrieval_chain  \n",
    "retriever = vector.as_retriever()  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI  \n",
    "llm = ChatOpenAI()  \n",
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "\n",
    "# 首先，我们需要一个可以传递给LLM来生成此搜索查询的提示\n",
    "# 能够搜索对话的\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"根据上面的对话，生成一个搜索查询来获取与对话相关的信息\")\n",
    "])\n",
    "# 接收对话历史并返回文档的chain\n",
    "# retriever：上面创建的数据索引\n",
    "retriever_chain = create_history_aware_retriever(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t llm, # 大模型\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t retriever, # 文档检索器\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t prompt) # 有历史对话并能基于历史对话来生成搜索查询（能够补全下面的问题？）\n",
    "\n",
    "from langchain_openai import ChatOpenAI  \n",
    "llm = ChatOpenAI()  \n",
    "\n",
    "# 由聊天记录生成的prompt，\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"根据下面的上下文回答用户的问题：\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "# 创建一个chain，将对话列表传递给大模型\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "# 创建一个检索链，用于检索文档（和对话）并将它们传递给下一个步骤。\n",
    "# 能够检索历史对话，即能够基于对话上下文，继续回答\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)\n",
    "\n",
    "# 封装的历史对话：之后通过Memory来实现？\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ],
   "id": "f4b18d9ecf5aaeef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d8a40940a4499da",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo",
   "language": "python",
   "name": "langchain-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
