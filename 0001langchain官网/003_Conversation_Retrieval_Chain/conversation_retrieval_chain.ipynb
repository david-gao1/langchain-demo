{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "到目前为止，我们创建的链只能回答单个问题。人们正在构建的LLM应用程序的主要类型之一是聊天机器人。那么我们如何将这个链转变为可以回答后续问题的链呢？",
   "id": "a7aa3ceb19ad4246"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # 检索器可以用于检索文档，协助大模型回答问题\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 通过langchain设置chatapi \n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 不设置环境变量的方式 ,非常不建议这么做\n",
    "#from langchain_openai import ChatOpenAI\n",
    "\n",
    "#llm = ChatOpenAI(api_key=\"...\")\n",
    "# 加载要索引的数据。为此，我们将使用WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()\n",
    "# 将其索引到向量存储中。\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# 构建我们的索引\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "# 现在，我们在向量存储中索引了这些数据，我们将创建一个检索链。该链将接收一个输入问题，查找相关文档，然后将这些文档连同原始问题一起传递给LLM，并要求它回答原始问题。\n",
    "# \n",
    "# 首先，让我们设置链来接收一个问题和检索到的文档，并生成一个回答。\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the following question based only on the provided context:\n",
    " \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    " \n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "# 如果我们想的话，可以直接传递文档来运行它：\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})\n",
    "# 然而，我们希望文档首先来自我们刚刚设置的检索器。\n",
    "# 这样，我们就可以使用检索器动态选择最相关的文档并将其传递给给定的问题。\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "# 现在，我们可以调用此链。这将返回一个词典-LLM的响应在answer键中。\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])"
   ],
   "id": "48feb53f7fbd330d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. prompt：使用提示模版\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "\n",
    "# 首先，我们需要一个可以传递给LLM来生成此搜索查询的提示\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # chat_history 来保存对话\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"根据上面的对话，生成一个搜索查询来获取与对话相关的信息\")\n",
    "])\n",
    "# 收集历史对话，并能够检索\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ],
   "id": "7f88700f255558a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#  在这些示例中，每个步骤都是预先确定的。 最后我们将创建一个代理人 - 在这种情况下，LLM决定要采取的步骤。\n",
    "\n",
    "# 添加搜索工具\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"搜索与LangSmith相关的信息。有关LangSmith的任何问题，您必须使用此工具！\",\n",
    ")\n",
    "tools = [retriever_tool]"
   ],
   "id": "3f26beda30152c00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# 加载线上的模版\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# 您需要设置OPENAI_API_KEY环境变量，或者将其作为参数`api_key`传递。\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# 创建基于openai的agent：检索对话的工具，官方的prompt\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 调用代理人并查看它的响应\n",
    "agent_executor.invoke({\"input\": \"langsmith如何帮助测试？\"})\n"
   ],
   "id": "1596d458055a0b58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "agent_executor.invoke({\"input\": \"旧金山的天气如何？\"})",
   "id": "314303029b2187b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chat_history = [HumanMessage(content=\"LangSmith可以帮助测试我的LLM应用程序吗？\"), AIMessage(content=\"可以！\")]\n",
    "agent_executor.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"告诉我如何进行\"\n",
    "})"
   ],
   "id": "4c6f82216cc5b97a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "60a2820355b4af23",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo",
   "language": "python",
   "name": "langchain-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
